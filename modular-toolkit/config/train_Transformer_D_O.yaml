datasets:
  name: AddModTransformerData
  frac_train: 0.2
  p: 97
  batch_size: 500
model:
  name: TransformerDecodeOnly
  transformer_config:
    vocab_size: 99
    embed_dim: 128
    norm_shape: 128
    ffn_num_hiddens: 256
    num_heads: 2
    num_layers: 2
    dropout: 0.01
  checkpoint_path: null
  strict_load: true
grokfast:
  name: grokfast_ema
  alpha: 0.98
  lamb: 3.5
  self_adoptive: True
  self_adoptive_rate: 0.001
loss:
  name: CrossEntropy
optimizer:
  name: AdamW
  lr: 0.0001
  weight_decay: 1.0
  betas:
  - 0.9
  - 0.999
  eps: 1.0e-08
train:
  eval_every: 10
  max_steps: 1000000.0
  stop_condi: 0.999
  stop_epochs: 1000
  log_dir: ./logs
  checkpoint_path: null
  save_every: 1000
  using_grokfast: 1
